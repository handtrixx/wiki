---
title: Die (beinahe) perfekte Website - Konzept
description: 
published: true
date: 2025-10-19T15:44:09.467Z
tags: 
editor: markdown
dateCreated: 2025-10-19T15:44:08.557Z
---

Willkommen zum ersten, wirklich langen Beitrag meiner Website, in dem ich darauf eingehe, was alles erforderlich ist um einen Internetauftritt besonders gut zu gestalten. Um zu beweisen, dass die gestellten Anforderungen auch erf√ºllt werden k√∂nnen, nutzen wir meine Domain niklas-stephan.de um das Gelernte, soweit m√∂glich, auch gleich direkt umzusetzen.

![01_setup_small.webp](/assets/wcms/concept/01_setup_small.webp){.align-center}

## Was ist perfekt?

Was ist schon perfekt und wer definiert das? Im Falle eines Internetauftritts ist diese Frage vielleicht einfacher zu beantworten als in anderen F√§llen. Denn, egal wie gut Gestaltung und Umsetzung gelungen sind, muss die Seite erst einmal von einem Besucher gefunden werden. Mit einem Markanteil von √ºber 90% (https://blog.hubspot.de/marketing/google-trends-suche) ist da die Google Suchmaschine eigentlich der einzige ausschlaggebende Faktor. Als Schlussfolgerung kann mann also sagen, dass die Optimierung einer Website auf von Google definierte Faktoren gleichzeitig nah an eine perfekte Website f√ºhrt. Welche Faktoren das sind und welche Weiteren noch eine wichtige Rolle spielen, sehen wir uns nun im ersten Teil unserer Artikelserie an.

## Aus Sicht des Besuchers

Neben viel Literatur und Informationen gibt Google mit dem Werkzeug ‚ÄúLighthouse‚Äù, welches in jede Installation des Browsers Chrome integriert ist, einen Einblick auf die Kriterien die sie an eine Website Stellen. Diese sind:

- Performance (Geschwindigkeit)
- Accessibility (Erreichbarkeit/Zugiffsf√§higkeit)
- Best Practices (Empfohlene Ma√ünahmen)
- Search Engine Optimization (SEO ‚Äì Suchmaschinenoptimierung)

![02_lighthouse.webp](/assets/wcms/concept/02_lighthouse.webp){.align-center}

Es taucht noch ein weiter Punkt ‚ÄúProgressive Web App‚Äù (PWA) in Lighthouse auf. Um aus HTML5 eine echte WebApp zu machen m√ºssen n√§mlich eine Menge von Anforderungen erf√ºllt werden. Dazu sp√§ter mehr in einem anderen Beitrag zu meiner App zur Hausautomatisierung. F√ºr eine Website im eigentlichen Sinn ist der Punkt PWA jedenfalls irrelevant. Der Screenshot hier zeigt eine Lighthouse Bewertung einer im Internet tausendfach frequentierten Seite, die aber offensichtlich nicht die gestellten Kriterien zu Googles voller Zufriedenheit erf√ºllt. Dies ist durchaus √ºblich bzw. nicht ungew√∂hnlich, denn noch viele weitere Faktoren entscheiden √ºber den Erfolg eines Internetauftritts.

Wen es interessiert wie diese Bewertung zustande kommt, der kann wie gesagt √ºber die Entwicklertools von Google Chrome (√ñffnen sich mit Taste F12) im Tab ‚ÄúLighthouse‚Äù eine beliebige Seite bewerten lassen und sich das Ergebnis ansehen. Praktischerweise gibt Lighthouse auch gleich noch Tipps dazu aus, wie sich die Punktzahl weiter erh√∂hen bzw. die Seite optimieren l√§sst.

Deshalb orientieren wir uns in den n√§chsten Kapiteln genau an diesen Faktoren.

### Performance

Seit dem die √úbertragungsgeschwindigkeit der Endger√§te des Webseitenbesuchers nicht mehr der limitierende Faktor sind, m√ºssen sich Webseiten mindestens genauso ‚Äúschnell‚Äù anf√ºhlen wie eine Applikation die auf unserem Endger√§t fest installiert ist. Google gibt in seinem Playbook so den dringlichen Rat dazu, dass eine Seite innerhalb von 2 Sekunden geladen sein muss um die Benutzererfahrung nicht zu schm√§lern. Um unter diesen 2 Sekunden zu bleiben kann man sich vieler Stellschrauben bedienen:

- Starke Infrastruktur / Hardware mit einer guten Netzwerkanbindung
- Ein m√∂glichst geringes Datenvolumen einer Seite
- Kompression von Dateien und w√§hrend der Daten√ºbertraung
- Reverse-Proxy Konfiguration und Caching
- Content Delivery Networks (CDN) f√ºr lokales Caching
- Kein/wenig Server-Side Rendering
- ‚ÄúSauberer‚Äù und sparsamer Quellcode
- Auf das (nach)laden, besonders von externen Inhalten, sollte m√∂glichst verzichtet werden

Jeder der aufgelisteten Punkte ist mindestens ein eigenes Kapitel Wert und wir werden in unsere Kapitelserie dementsprechend darauf eingehen.

### Accessibility
Egal wie schnell sich die von uns aufgesuchte Seite auch aufgebaut hat, wenn der Autor meinte es sei eine gute Idee alles in einer Schriftgr√∂√üe von 5 Pixeln in hellgrauer Schrift unter Verwendung eines Comic Sans Fonts auf wei√üem Hintergrund anzuzeigen, ist der Spa√ü vorbei. Auch Laufschriften mit Telefonnummern zum Abschreiben und gro√üz√ºgige Nutzung von Neon-Farben sind Effekte die in einem h√∂chstens die Gewaltbereitschaft steigern. Vielleicht nicht ganz so √ºbertrieben aber √§hnlich hat sicherlich jeder von uns schon einmal Erfahrungen im Internet gemacht. Um solchen Situationen entgegenzuwirken achtet man als Webseitenbetreiber, neben der generellen User Experience (UX ‚Äì Berufserfahrung), auch auf die Accessibility, sprich die Erreichbarkeit / Zugriffsf√§higkeit seiner Inhalte. Dabei gilt es zu bedenken:

#### Nicht jeder Mensch kann gut sehen

Manche Menschen k√∂nnen √ºberhaupt nicht sehen und lassen sich die Inhalte von einer Maschine vorlesen
Menschen nutzen unterschiedliche Endger√§te mit unterschiedlichen Aufl√∂sungen
Auf die Verwendung evtl. verwirrender Effekte sollte man m√∂glichst verzichten, wenn sie nicht ein Kernelement der Seite darstellen.
Die Seitenstruktur sollte klar und hierarchisch sein, z.B. nicht am Anfang der Seite mit einer h4 √úberschrift anfangen und dann mitten im Text h2 verwenden.
Es sollten m√∂glichst keine oder zumindest nur wenige Ma√ünahmen getroffen werden, die den Nutzer daran hindern die Darstellung seinen Bed√ºrfnissen nach anzupassen.
Wenn mann sich daran h√§lt, wird man auf modernen Endger√§ten/Browsern automatisch durch die Bereitstellung seiner Seite mit der ‚ÄúReader‚Äù Option belohnt, die ein eBook-artiges lesen der Artikel erm√∂glicht.

### Best Practices

Es gibt eine Reihe von empfohlenen Ma√ünahmen um die korrekte Darstellung der Seite beim Besucher zu Gew√§hrleisten und um bestimmte Sicherheitsstandards einzuhalten. Au√üerdem pr√ºft Lighthouse hier noch, dass die Seite keine offensichtlichen Fehler in der Programmierung enth√§lt und g√§ngige sowie akutelle Standardtechniken umgesetzt wurden. Insgesamt werden bis zu 17 Kriterien gepr√ºft, von denen ich hier die wichtigsten Aufliste.

#### Verwendung von https zur Verschl√ºsselung der Daten√ºbertragung zwischen Nutzer und Betreiber. 
Schon vor 2021 eigentlich ein absolutes Muss.

### Verzicht auf nicht unbedingt erforderliche JavaScript Features

#### Keine JavaScript Fehler auf der Seite.
Korrekte Formatierung des HTML Codes bez√ºglich wesentlicher Merkmale wie z.B. der eingesetzten Sprache.
Das klingt eigentlich nach nicht viel und leicht umzusetzen. Wer sich aber einmal die M√ºhe macht sich die Fehlerprotokolle durchzulesen die von einer gro√üen Anzahl g√§ngiger Websites ‚Äúausgespuckt‚Äù werden, staunt nicht schlecht. Offenbar ist es selbst gro√üen Unternehmen nur schwer m√∂glich, ihre Entwickler dahingehend zu motivieren, dass solche Fehler ausgeschlossen sind. Zur Verteidigung der Entwickler aber vor allem deren Motivation, muss man allerdings sagen dass verschiedene Browser gerade mit JavaScript verschieden umgehen und manchmal Kompromisse geschlossen werden m√ºssen.

### SEO
Wie schon zu Beginn des Artikels erl√§utert, bringt uns die sch√∂nste Website nichts, wenn sie niemand findet. Falls wir dann auch noch nicht gewillt sind tief in unsere Taschen zu greifen, um Werbekampagnen zu finanzieren, dann aber eigentlich auch immer m√ºssen wir uns mit Search Engine Optimization (SEO) besch√§ftigen. Fr√ºher bestand die Optimierung f√ºr Suchmaschinen zum gro√üen Teil darin, brav ein paar Schl√ºsselw√∂rter (Keywords) in die Meta Informationen unseres Auftritts einzubauen. Das reicht heute bei weitem nicht mehr aus und die vergebenen Keywords werden sogar in der Regel von den g√§ngigen Suchmaschinen gar nicht mehr beachtet. Daf√ºr sind nun eine Vielzahl anderer Faktoren entscheidend daf√ºr ob wir (gut) gefunden werden oder nicht. Einige der wichtigsten davon sind hier aufgelistet:

- Die Seite enth√§lt Metainformationen, wie: Beschreibung, Titel, Bild, Link, usw.
- Die Seite hat einen l√§ngeren wirklichen Inhalt in Textform
- M√∂glichst alle Links auf der Seite haben eine Beschreibung (Text)
- Alle Bilder auf der Seite haben eine Bezeichnung (alt)
- die Seite ist z.B. √ºber eine robots.txt Datei so eingestellt, dass sie von Suchmaschinen indiziert werden darf
- die robots.txt enth√§lt, wenn vorhanden, keine Fehler
- Es werden keine ‚ÄúMini‚Äù Schriftgr√∂√üen verwendet um Inhalte vorzut√§uschen (eine Zwischenzeitlich verbreitete Masche unseri√∂ser Anbieter)
- Die Seite / Der Beitrag enth√§lt interne und externe Links zu anderen Seiten

Wie man sieht zielen diese Kriterien darauf ab, dass neben den Metainformationen die auch f√ºr Soziale Netzwerke relevant sind, der komplette Seiteninhalt bei der Indizierung der Seite durch Suchmaschinen ber√ºcksichtigt wird. Das ist auch ein weiteres Argument, neben der Performance, Inhalte nicht dynamisch nachzuladen, weil eben diese dann von Google&Co nicht gefunden werden.

### Social Media

Aus Sicht eines Unternehmens heute beinahe √ºberlebensnotwendig, aus Sicht einer Privatperson einfach eine hilfreiche Unterst√ºtzung um Inhalte bekannt zu machen und mit der Welt zu teilen, das ist Social Media Integration f√ºr eine Website. Die schon zuvor genannten Meta-Informationen erm√∂glichen es, dass beim Teilen eines Links automatisch ein Bild, eine √úberschrift und eine Kurzbeschreibung generiert werden. Au√üerdem ermutigen Schaltfl√§chen mit den Symbolen der verschiedenen Netzwerke in der N√§he eines Beitrags zum Teilen. Man kann auch ber√ºcksichtigen, dass je nach Endger√§t unterschiedliche Kan√§le genutzt werden. So macht ein Share Button zu WhatsApp in der Regel nur f√ºr mobile Endger√§te Sinn. Auch werden von unterschiedlichen Altersgruppen unterschiedliche Netzwerke bevorzugt. Dabei kann man sich hieran orientieren:

- Facebook: Wird prim√§r von Menschen mittleren bis h√∂heren Alters genutzt, ist aber wohl jedem als Pionier bekannt.
Instagram: Junge Erwachsene bis Menschen mittleren Alters nutzen dieses Netzwerk haupts√§chlich zum Teilen von Bildern und Geschichten dazu.

- TikTok: F√ºr die ganz jungen Mitmenschen. Da wird wohl haupts√§chlich getanzt, geklatscht und dazu gesungen, um das Ganze dann auch noch als Video zu teilen.

- Twitter(X): zum Austausch von Kurznachrichten und so richtig im sogenannten Arabischen Fr√ºhling weltweit bekannt geworden. Bis vor kurzem auch Stammsitz einer orangen Ente. Zielpublikum sind inzwischen eher Menschen mittleren bis h√∂heren Alters.

- YouTube: Mit etwas Aufwand auch als Soziales Netzwerk nutzbar, wird daf√ºr aber altersgruppen√ºbergreifend genutzt

- WhatsApp: eher zum pers√∂nlichen Austausch in kleineren Zielgruppen, daf√ºr aber ebenfalls altersgruppen√ºbergreifend.

Nat√ºrlich gibt es auch regionale Unterschiede bei der Nutzung der Netzwerke, so sieht in China oder Indien das Bild schon wieder ganz anders aus. Z.B. tritt dort der Anbieter WeChat mit seiner App als eierlegende Wollmilchsau auf.

### Browser Kompatibilit√§t

Hier muss man eine Entscheidung treffen. Leider nutzen nach wie vor viele Menschen den v√∂llig veralteten Internetbrowser ‚ÄúInternet Explorer‚Äù (IE11) von Microsoft. Dieser wird schon seit l√§ngerem nicht mehr von Microsoft weiterentwickelt und wurde durch ‚ÄúEdge‚Äù ersetzt. Da nun aber viele trotzdem noch den IE11 nutzen, ist die zu treffende Entscheidung: Will ich diese Besucher ebenfalls mit einer fehlerfreien Darstellung bedienen oder schlie√üe ich sie aus, damit ich mich bei der Erstellung der Seite an aktuelle Standards halten kann und diverse Altlasten nicht ber√ºcksichtigen muss. Ich habe mich gegen die Unterst√ºtzung des IE11 entschieden, da selbst Microsoft nach Supportende von Windows 7, an welches der IE11 gekoppelt ist, diesen als Sicherheitsrisiko einzustufen plant. Die anderen √ºblichen Browser wie Google Chrome, Chromium und Microsoft Edge oder auch Apple Safari liefern stets gute Ergebnisse. Das Open Source Projekt Firefox der Mozilla Gruppe ist die Wahl des Nutzers mit Wunsch nach Unabh√§ngigkeit. Auch Firefox stellt die meisten Inhalte des aktuellen HTML Standards korrekt dar und unterst√ºtzt nur z.B. einige exotischere Parameter in CSS nicht.

### User Experience und Layout

F√ºr ein Unternehmen sicherlich nicht nur ein Unterpunkt f√ºr mich als Privatperson mehr eine Hilfe. Unter User Experience (UX) wird die komplette Berufserfahrung die der Besucher w√§hrend des Besuchs unserer Website macht zusammengefasst. Dazu geh√∂rt das Layout oder auch User Interface (UI) unserer Seite als Kernelement. Sich wiederholende Elemente sollten auf allen (Unter)Seiten gleich aussehen und generell sollte w√§hrend des kompletten Besuchs eine Wiedererkennungswert geschaffen werden. So sind Buttons immer an der gleichen Stelle zu finden, verhalten sich identisch und sehen gleich aus. Auch das Farbschema sowie die komplette Formatierung der Inhalte sollten durchg√§ngig und ansprechend sein. Ich vertraue hierzu als Einstieg schon seit einigen Jahren auf das Open Source Projekt ‚ÄúBootstrap‚Äù (Link) von Twitter. Dieses beinhaltet im wesentlichen vorgefertigte CCS (Styles) die nach belieben verwendet werden und ggfs. auch angepasst werden k√∂nnen. Bootstrap hatte zwischenzeitlich etwas an seinem guten Ruf eingeb√º√üt, weil es lange auf das JavaScript Framework ‚ÄújQuery‚Äù gesetzt hat. Mit der aktuellen Version 5 ist das Geschichte und wir freuen uns √ºber einen kleineren Quellcode bei der Einbindung.

## Aus Sicht des Betreibers

In den vorherigen Kapiteln haben wir herausgefunden, was aus Sicht von Google bei der Ausspielung einer Website relevant ist. Nat√ºrlich haben wir aber neben den Anforderungen aus Besuchersicht auch noch sowohl als Autor als auch als Administrator weitere Anforderungen. Einige davon werde ich hier anf√ºhren, andere sp√§ter in der Artikelserie auch noch tiefgreifender ausf√ºhren.

### Server

Wie zuvor im Punkt Performance schon beschrieben ist ein schneller Server mit einer sehr guten Netzwerkanbindung ans Internet eines der Kernkriterien f√ºr eine performante Website. Anbieter f√ºr virtuelle oder physische Server gibt es viele. Einige der Bekanntesten sind Hetzner, 1blu, Netcup oder Strato. Man hat also die Qual der Wahl. Heute immer mehr √ºblich ist anstelle des Betriebs eines eigenen Servers, die Nutzung von Ressourcen eines Cloud Anbieters. Hier Stellen Google, Amazon und Microsoft die Platzhirsche dar. Aus Sicht des Datenschutzes stellen alle drei Anbieter mittlerweile auch Ressourcen aus Deutschland bereit und halten sich dementsprechend an die hier g√ºltigen Regulierungen. Ich pers√∂nlich bin aber aufgrund der variablen Abrechnung kein Fan der Cloud Anbieter und bezahle lieber einen monatlichen fixen Betrag der s√§mtlichen Traffic sowie die Hardwarekosten beinhaltet.

### Monitoring & Alerting

Das Monitoring, also die √úberwachung des Serves ist nicht nur in Problemf√§llen wichtig, sondern hilft auch dabei Problemen bereits entgegen zur wirken bevor sie auftreten. Ich nutze zum Monitoring das mit dem CentOS Betriebsystem ausgelieferte Open Source Tool Cockpit, welches eine schicke Weboberfl√§che f√ºr die meisten anliegen liefert. So lassen sich dort automatische Updates und eine Langzeit-Ressourcen√ºberwachung inkl. Dashboard mit ein paar Mausklicks aktivieren.

Viele setzen ein Alerting, also die Alarmierung im Fehlerfall, mit einem Monitoring gleich. Das ist so nicht ganz korrekt. Ein Alerting kann durchaus v√∂llig unabh√§ngig vom Monitoring konfiguriert und genutzt werden. So nutze ich z.B. nur Alerts die mir eine E-Mail senden wenn meine Website keinen g√ºltigen Inhalt zur√ºck liefert. Wem das reicht, der braucht keine schwergewichtige Softwarel√∂sung zu installieren. Wichtig ist nur: Die √úberwachung sollte auf keinen Fall auf dem gleichen Serversystem wie unsere Website laufen. Der Grund ist klar: Wenn der Server ausf√§llt kann er mir auch keine E-Mails mit der Info √ºber den Ausfall liefern‚Ä¶ Deshalb kommen meine Mails von einem kleinen Raspberry PI der zuhause auch schon vorher seinen 24-Stunden Dienst verrichtet hat. Und im Normalfall kommen eigentlich auch gar keine Mails, weil der Server einfach nicht ausf√§llt üôÇ

### Datensicherung

Das eine Datensicherung zwingend erforderlich ist, braucht man heute gl√ºcklicherweise niemanden mehr zu erkl√§ren. Ich nutze f√ºr die Website genauso wie vor andere Komponenten auf meinem Server eine mehrschichtige Backupstrategie: Eine t√§gliche Spiegelung der Inhalte innerhalb der Servers l√§sst mich versehentlich gel√∂schte Inhalte sehr schnell wiederherstellen. Diese Spiegelung ist dann auch die Quelle um die Daten inkrementell abgesichert an den zuvor erw√§hnten Raspberry Pi zuhause zu √ºbertragen. Genau genommen an ein dahinter liegendes Hardware RAID Plattensystem. So habe ich zumindest alles mir m√∂gliche getan um sowohl das versehentliche L√∂schen, einen Datenverlust oder einem Datentr√§gerausfall entgegen zu wirken.

### Domain und DNS
Die Adresse(n) unter denen wir im Internet erreichbar sein wollen werden als Domains bezeichnet. Diese sichert man sich f√ºr geringes Geld bei einer Vielzahl von Anbietern, wenn man einen kreativen und nicht bereits belegten Namen gefunden hat. Und genau da liegt die Schwierigkeit, die meisten ‚Äúh√ºbschen‚Äù Namen sind bereits vergeben und man muss wirklich kreativ werden. Eine Nacht dar√ºber zu schlafen bevor man die Registrierung anst√∂√üt kann wirklich helfen.

Der DNS Eintrag ist das Bindeglied im Internet zwischen unseren registrierten Domains und der IP-Adresse unseres Servers. Oft √ºbernehmen Anbieter von Domains auch gleichzeitig die Registrierung und Verteilung des DNS Eintrags f√ºr genauso geringes Geld.

### Sicherheit

Neben dem eigentlich schon verpflichtenden Einsatz von Verschl√ºsselung √ºber https://, welche auf meinem Server √ºber das Open Source Tool ‚ÄúNginx Proxy Manager‚Äù (Link) einrichte, kann man noch mehr f√ºr die Sicherheit von Besuchern und uns als Betreibern tun. Ein gro√üer Mehrwert zur Sicherheit ist w√§hrend der Umsetzung als Nebenprodukt entstanden. Da ich ausschlie√ülich statische Seiten generiere und auf den Einsatz von Cookies verzichte, beschr√§nkt sich der Besucher dieser Seiten fast vollst√§ndig auf den blo√üen Download von Dateien ohne Nachladen weiterer Inhalte. Eine Ausnahme spielen die Assets (Bilder, Dokumente, etc.), aber dazu sp√§ter mehr.

Au√üerdem sollte nat√ºrlich der Zugang zum Server gesichert werden. So ist eine Firewall zu aktivieren und Standardports z.B. f√ºr SSH sind zu vermeiden. Auch empfiehlt es sich z.B. mit dem Open Source Tool Google Authenticator eine 2-Faktor Anmeldung am Server zu erzwingen. Eine Verschl√ºsselung der Daten auf dem Datentr√§gern des Servers ist, wenn m√∂glich, sicherlich auch keine schlechte Idee. F√ºr den Root user deaktivieren wir noch die M√∂glichkeit sich aus der Ferne anzumelden und f√ºhren selbst unsere Kommandos niemals direkt als dieser aus.

### Content Mangagment System

Eine immer popul√§rer werdende Praxis ist der Einsatz eines sogenannten Headless Content Management Systems (CMS) zur Datenhaltung, Verwaltung und ggfs. zum editieren von Beitragen wie diesem hier. Headless bedeutet dass das CMS die in ihm gepflegten Daten nicht direkt sondern nur √ºber Webschnittstellen bereit stellt. Das hat, neben den Vorteilen der Modularisierung und Unabh√§ngigkeit, den Vorzug dass wir unsere Inhalte zur Generierung von statischen Seiten an jedem Punkt unserer Prozesses abfragen k√∂nnen ohne dabei auf Limitierungen des CMS selbst gefesselt zu sein. Ich nutze hierf√ºr das Open Source Tool ‚ÄúCockpit‚Äù (Link), und bin nach einer kurzen Einarbeitungszeit von vielleicht 6 Stunden hellauf begeistert. Das einzig verwirrende ist der Name. Wir erinnern uns: Unser Monitoring Tool heisst ebenfalls Cockpit. Die beiden haben so rein gar nichts miteinander zu tun, sondern teilen sich einfach den Namen.

### Asset Management

Im Falle unserer Website sind unsere Assets vornehmlich Bilder. Und diese m√∂chten wir gerne, √§hnlich wie unsere Inhalte, autark gespeichert und verwaltet wissen. Au√üerdem soll unser Asset Management System dazu in der Lage sein, aus den von uns hochgeladenen Bildern automatisch Miniaturen (Thumbnails) zu erstellen. Gl√ºcklicherweise kann unser CMS System ‚ÄúCockpit‚Äù (Link) das alles von Haus aus und bietet f√ºr den Zugriff auch noch Web Services, mit deren Verwertung wir bereits bekannt sind. In Cockpit ist das Asset Management ein vom CMS getrennter Bereich der aber von dort aus auch angesprochen werden kann, so dass wir Bilder beim Schreiben eines Artikels direkt hochladen und einf√ºgen k√∂nnen.

### Backend

Oft habe ich in diesem Artikel √ºber die Generierung von statischen Seiten gesprochen. Aber womit machen wir das eigentlich? Hier bin ich einen un√ºblichen Weg gegangen, und verwende das Open Source Tool Node-RED (Link). Node-RED ist eine sogenannte Low-Code Programmierumgebung auf die √ºber den Browser zugegriffen wird. Low-Code heisst das man Abl√§ufe von einfacher bis mittlerer Komplexit√§t ohne eigentliche Programmierung abbilden kann. Allerdings lassen sich auch jederzeit eigene Funktionen einbinden, wovon ich auch h√§ufig gebrauch machen. Verschiedene Prozessschritte lassen sich grafisch miteinander verbinden, so dass als Nebenprodukt gleich noch ein Ablaufdiagramm entsteht. Ich nutze das Tool schon seit mehren Jahren z.B. zur Heimautomatisierung, was die Vielseitigkeit widerspiegelt. Es gibt aber auch noch eine Vielzahl anderer Tools die auf die Generierung von statischen Websites spezialisiert sind.

### Reporting & Web Analytics

Wenn man so viel Arbeit in die Erstellung von Inhalten und Struktur steckt, m√∂chte man nat√ºrlich auch wissen ob und wie diese bei den Besuchern ankommen. Auch wie viele Besucher es √ºberhaupt in welchem Zeitraum gibt und ob sie l√§ngere Zeit auf unseren Seiten bleiben interessiert uns. Wenn unsere Inhalte au√üerdem in mehreren Sprachen oder zumindest auch in Englisch oder Spanisch angeboten werden, dann m√∂chten wir auch wissen woher die Besucher kommen. Um all diese Fragen zu beantworten gibt es sogenannte Web Analytics Tool. Solch ein Tool bereitet die Antworten auf diese Fragestellungen in der Regel auch gleich noch grafisch auf. Das bekannteste unter ihnen ist sicherlich Google Analytics, welches sich kostenfrei in eine Website einbinden l√§sst. Allerdings ist Google Analytics aus Gesichtspunkten des Datenschutzes nicht besonders sparsam und l√§sst sich auch nicht selbst betreiben, sondern greift auf die Google Cloud Services zur√ºck. Als Freund des Datensch√ºtzers hat sich hingegen das Open Source Tool ‚ÄúMatomo‚Äù (Link) erwiesen. Au√üerdem l√§sst es sich selbst betreiben, ist flink und geht auf alle genannten Bed√ºrfnisse ein. In Matomo l√§sst sich auch einstellen, dass Daten nur anonymisiert erhoben werden und z.B. keine IP-Adressen der Besucher gespeichert werden.

### Datenschutz & Rechtliche Bestimmungen
Wo wir schon das Thema Datenschutz angesprochen haben, ohne darauf gegen√ºber dem Webseitenbenutzer einzugehen geht es in Deutschland bzw. der EU nicht. Das ich mich gegen den Einsatz jeglicher Art von Cookies entscheide, vereinfacht diesen Teil aber ungemein (Stichwort: Cookie-Madness). So muss auf der gesamten Webseite aber trotzdem ein stets und einfach auffindbarer Bereich/Link zu den Datenschutzbestimmungen verf√ºgbar gemacht werden. Das gute ist aber: Datensch√ºtzer sind keine Unmenschen, im Gegenteil sogar. Sie wollen uns nur vor unlauteren Gesch√§ftspraktiken der Betreiber sch√ºtzen und sind gegen lange komplizierte ‚ÄúParagraphenauflisterei‚Äù. Das heisst, dass die Datenschutzbestimmungen m√∂glichst kurz und verst√§ndlich formuliert sein sollen. Sie sollten au√üerdem keine Abschnitte enthalten die f√ºr die Website gar nicht relevant sind und im Wesentlichen folgendes enthalten:

- Welche pers√∂nlichen Daten werden gespeichert?
- Wo werden die Daten gespeichert?
- Von wem werden die Daten gespeichert?
- Wer ist Verantwortlicher Ansprechpartner?
- Wer darf die Daten auswerten?
- Welche Drittparteien sind evtl. involviert?
- Wie kann eine L√∂schung meiner evtl. vom Betreiber gespeicherten Daten initiiert werden?

Wie gesagt m√ºssen aus der Liste nicht alle Punkte relevant sein, z.B. wenn √ºberhaupt keine personalisierten Daten gespeichert werden. Das heisst dass vorgefertigte Texte nicht unbedingt gut sind und vor allem meistens Passagen enthalten die gek√ºrzt/entfernt werden sollten. Nat√ºrlich bin ich kein Anwalt und die rechtlichen Grundlagen √§ndern sich zur Zeit quartalsweise, aber wenn man sich an diese Grundlagen zum Datenschutz h√§lt ist man auf jeden Fall gute dabei und handelt bedachter als viele andere Webseitenbetreiber.

Aus rechtlicher Sicht muss ebenso immer eine Impressum verf√ºgbar sein. Hier kann man sich durchaus an Vorlagen aus dem Internet bedienen, da es sich im Gegensatz zur Datenschutzerkl√§rung hier eher um unsere Absicherung gegen√ºber dem Nutzer und keine Dienstleistung f√ºr ihn handelt. Pflichtangaben sind:
- Verantwortlicher f√ºr das Angebot gem√§√ü ¬ß 5 TMG / ¬ß 18 MStV
- Inhaltlich Verantwortlicher gem√§√ü ¬ß 18 Abs. 2 MStV

Beide Angaben sollten den vollst√§ndigen Namen, ein Adresse und zumindest eine E-Mail Anschrift enthalten. Hier z√§hlen leider keine Argumente aus Sicht des Datenschutzes f√ºr den Betreiber‚Ä¶

### Fazit und Ausblick

Wir kennen nun viele Kriterien die eine perfekte Website ausmachen und k√∂nnen bereits sagen, dass sich diese so mit einem Homepagebaukasten oder einem Web Content Managementsystem wie z.B. WordPress nicht umsetzen lassen. In den Folgeartikeln meiner Serie werden wir allerdings auch sehen, dass zur Umsetzung teilweise tiefgreifendes IT-Verst√§ndnis ben√∂tigt wird. Deshalb Rate ich allen die sich nicht so tief mit dieser Materie auseinander setzen m√∂chten trotzdem zum Einsatz von WordPress. Bei WordPress handelt es sich um ein millionenfach eingesetztes WCMS mit dem man schnell zu passablen Ergebnissen kommen kann und der Umsetzungsaufwand sich auch von Laien bew√§ltigen l√§sst.

Zusammengefasst ist folgender Anforderungskatalog:

- Hosting (Bereitstellung) auf einem flinken Server als Basis
- Eine performante Netzwerkanbindung dieses Servers an das Internet
- DNS Eintr√§ge unser Domain(s)beim einem vertrauensw√ºrdigem Anbieter
- Virtualisierung einzelner Komponenten in sogenannten Containern
- Server Monitoring mit Cockpit (nicht das CMS Tool)
- Alerting mit einer geeigneten schlanken L√∂sung
- Eine Reverse Proxy Konfiguration inkl. Zertifikatsmanagement mit NGINX Proxy Manager
- Ein Backend auf Basis von Node-Red zur Generierung statischer Seiten
- Content und Asset Management mit Cockpit (nicht das Monitoring Tool)
- Web Analytics mit Matomo
- Einen Texteditor und Zugriff auf eine Shell mit Microsoft Visual Studio Code
- HTML5 Quellcode mit Unterst√ºtzung von Twitter Bootstrap 5 (also ohne jQuery) Komponenten
- Individuelle Stylesheets mit CSS Variablen
- Vanilla (keine Framework wie jQuery oder Angular) Javascript im Frontend

In dieser Reihenfolge werde ich die Themen in den folgenden Artikeln auch beschreiben.
Um noch etwas Spannung aufzubauen:
Eine Lighthouse Berwertung von 100% Punkten in allen Bereichen l√§sst sich umsetzen, diese Seite hier ist der Beweis :-).
